{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/MouseViT/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from src.zig_model import ZIG\n",
    "\n",
    "# 1) Load .env\n",
    "load_dotenv()\n",
    "\n",
    "# 2) Import your pipeline steps + the allen_api\n",
    "from src.data_loader import allen_api\n",
    "from src.pipeline_steps import (\n",
    "    AnalysisPipeline,\n",
    "    AllenStimuliFetchStep,\n",
    "    ImageToEmbeddingStep,\n",
    "    StimulusGroupKFoldSplitterStep,\n",
    "    MergeEmbeddingsStep\n",
    ")\n",
    "from transformers import ViTModel, ViTImageProcessor\n",
    "\n",
    "def make_container_dict(boc):\n",
    "    experiment_container = boc.get_experiment_containers()\n",
    "    container_ids = [dct['id'] for dct in experiment_container]\n",
    "    eids = boc.get_ophys_experiments(experiment_container_ids=container_ids)\n",
    "    df = pd.DataFrame(eids)\n",
    "    reduced_df = df[['id', 'experiment_container_id', 'session_type']]\n",
    "    grouped_df = reduced_df.groupby(['experiment_container_id', 'session_type'])[\n",
    "        'id'].agg(list).reset_index()\n",
    "    eid_dict = {}\n",
    "    for row in grouped_df.itertuples(index=False):\n",
    "        c_id, sess_type, ids = row\n",
    "        if c_id not in eid_dict:\n",
    "            eid_dict[c_id] = {}\n",
    "        eid_dict[c_id][sess_type] = ids[0]\n",
    "    return eid_dict\n",
    "\n",
    "def main():\n",
    "    # A) Allen BOC\n",
    "    boc = allen_api.get_boc()\n",
    "\n",
    "    # B) Container dict\n",
    "    eid_dict = make_container_dict(boc)\n",
    "    print(len(eid_dict), \"containers found.\")\n",
    "\n",
    "    # C) Session->stimuli mapping\n",
    "    stimulus_session_dict = {\n",
    "        'three_session_A': ['natural_movie_one', 'natural_movie_three'],\n",
    "        'three_session_B': ['natural_movie_one', 'natural_scenes'],\n",
    "        'three_session_C': ['natural_movie_one', 'natural_movie_two'],\n",
    "        'three_session_C2': ['natural_movie_one', 'natural_movie_two']\n",
    "    }\n",
    "\n",
    "    # D) HF model + processor\n",
    "    processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "    model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "    # E) Embedding cache dir\n",
    "    embedding_cache_dir = os.environ.get('TRANSF_EMBEDDING_PATH', 'embeddings_cache')\n",
    "\n",
    "    # F) Build pipeline with all steps\n",
    "    pipeline = AnalysisPipeline([\n",
    "        AllenStimuliFetchStep(boc),\n",
    "        ImageToEmbeddingStep(processor, model, embedding_cache_dir),\n",
    "        StimulusGroupKFoldSplitterStep(boc, eid_dict, stimulus_session_dict, n_splits=10),\n",
    "        MergeEmbeddingsStep(),  # merges the neural folds with the image embeddings\n",
    "    ])\n",
    "\n",
    "    # G) Run pipeline on a single container/session/stimulus\n",
    "    container_id = 511498742\n",
    "    #session = 'three_session_A'\n",
    "    #stimulus = 'natural_movie_three'\n",
    "    session='three_session_B'\n",
    "    stimulus='natural_scenes'\n",
    "    result = pipeline.run((container_id, session, stimulus))\n",
    "\n",
    "    # H) Print final results\n",
    "    print(\"\\n=== FINAL PIPELINE OUTPUT ===\")\n",
    "    print(\"Keys in 'result':\", list(result.keys()))\n",
    "    #  'raw_data_dct', 'embedding_file', 'folds', 'merged_folds', etc.\n",
    "\n",
    "    print(f\"Embedding file path: {result['embedding_file']}\")\n",
    "    folds = result['folds']\n",
    "    print(f\"Number of folds: {len(folds)}\")\n",
    "\n",
    "    merged_folds = result['merged_folds']\n",
    "    for i, fold_data in enumerate(merged_folds, start=1):\n",
    "        (Xn_train, Xe_train, Xn_test, Xe_test, frames_train, frames_test) = fold_data\n",
    "        print(f\"\\nFold {i}:\")\n",
    "        print(f\"  Xn_train: {Xn_train.shape}, Xe_train: {Xe_train.shape}\")\n",
    "        print(f\"  Xn_test : {Xn_test.shape},  Xe_test : {Xe_test.shape}\")\n",
    "        print(f\"  frames_train: {frames_train.shape}, frames_test: {frames_test.shape}\")\n",
    "\n",
    "    return merged_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540 containers found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOOM /home/maria/Documents/HuggingMouseData/MouseViTEmbeddings/google_vit-base-patch16-224_embeddings.pkl\n",
      "Found existing embeddings for model google_vit-base-patch16-224. Using file:\n",
      " /home/maria/Documents/HuggingMouseData/MouseViTEmbeddings/google_vit-base-patch16-224_embeddings.pkl\n",
      "      frame  start    end\n",
      "0        41  16101  16108\n",
      "1        64  16109  16116\n",
      "2        91  16116  16123\n",
      "3        17  16124  16131\n",
      "4        99  16131  16138\n",
      "...     ...    ...    ...\n",
      "5945     23  96067  96074\n",
      "5946     91  96074  96081\n",
      "5947     10  96082  96089\n",
      "5948     78  96089  96096\n",
      "5949     31  96097  96104\n",
      "\n",
      "[5950 rows x 3 columns]\n",
      "(5900, 171)\n",
      "\n",
      "=== FINAL PIPELINE OUTPUT ===\n",
      "Keys in 'result': ['container_id', 'session', 'stimulus', 'raw_data_dct', 'embedding_file', 'folds', 'merged_folds']\n",
      "Embedding file path: /home/maria/Documents/HuggingMouseData/MouseViTEmbeddings/google_vit-base-patch16-224_embeddings.pkl\n",
      "Number of folds: 10\n",
      "\n",
      "Fold 1:\n",
      "  Xn_train: (5300, 171), Xe_train: (5300, 768)\n",
      "  Xn_test : (600, 171),  Xe_test : (600, 768)\n",
      "  frames_train: (5300,), frames_test: (600,)\n",
      "\n",
      "Fold 2:\n",
      "  Xn_train: (5300, 171), Xe_train: (5300, 768)\n",
      "  Xn_test : (600, 171),  Xe_test : (600, 768)\n",
      "  frames_train: (5300,), frames_test: (600,)\n",
      "\n",
      "Fold 3:\n",
      "  Xn_train: (5300, 171), Xe_train: (5300, 768)\n",
      "  Xn_test : (600, 171),  Xe_test : (600, 768)\n",
      "  frames_train: (5300,), frames_test: (600,)\n",
      "\n",
      "Fold 4:\n",
      "  Xn_train: (5300, 171), Xe_train: (5300, 768)\n",
      "  Xn_test : (600, 171),  Xe_test : (600, 768)\n",
      "  frames_train: (5300,), frames_test: (600,)\n",
      "\n",
      "Fold 5:\n",
      "  Xn_train: (5300, 171), Xe_train: (5300, 768)\n",
      "  Xn_test : (600, 171),  Xe_test : (600, 768)\n",
      "  frames_train: (5300,), frames_test: (600,)\n",
      "\n",
      "Fold 6:\n",
      "  Xn_train: (5300, 171), Xe_train: (5300, 768)\n",
      "  Xn_test : (600, 171),  Xe_test : (600, 768)\n",
      "  frames_train: (5300,), frames_test: (600,)\n",
      "\n",
      "Fold 7:\n",
      "  Xn_train: (5300, 171), Xe_train: (5300, 768)\n",
      "  Xn_test : (600, 171),  Xe_test : (600, 768)\n",
      "  frames_train: (5300,), frames_test: (600,)\n",
      "\n",
      "Fold 8:\n",
      "  Xn_train: (5300, 171), Xe_train: (5300, 768)\n",
      "  Xn_test : (600, 171),  Xe_test : (600, 768)\n",
      "  frames_train: (5300,), frames_test: (600,)\n",
      "\n",
      "Fold 9:\n",
      "  Xn_train: (5350, 171), Xe_train: (5350, 768)\n",
      "  Xn_test : (550, 171),  Xe_test : (550, 768)\n",
      "  frames_train: (5350,), frames_test: (550,)\n",
      "\n",
      "Fold 10:\n",
      "  Xn_train: (5350, 171), Xe_train: (5350, 768)\n",
      "  Xn_test : (550, 171),  Xe_test : (550, 768)\n",
      "  frames_train: (5350,), frames_test: (550,)\n"
     ]
    }
   ],
   "source": [
    "merged_folds = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_fold(merged_folds, fold, model_path=\"/home/maria/MouseViT/trained_models/zig_model_fold.pth\", save_path=None):\n",
    "    \"\"\"\n",
    "    Evaluates the trained ZIG model on a specific test fold and computes the likelihood of the observed data \n",
    "    under the model.\n",
    "\n",
    "    Args:\n",
    "        merged_folds (list): List of folds containing (Xn_train, Xe_train, Xn_test, Xe_test, frames_train, frames_test).\n",
    "        fold (int): The fold number to evaluate.\n",
    "        model_path (str): Path to the trained model checkpoint.\n",
    "        save_path (str, optional): If provided, saves the test probabilities as a .npy file.\n",
    "\n",
    "    Returns:\n",
    "        test_likelihoods (numpy.ndarray): A 2D NumPy array (num_neurons, num_time_points) containing the likelihood of each test data point.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the trained model\n",
    "    checkpoint = torch.load(model_path, map_location=\"cpu\")  # Load model to CPU\n",
    "    Xn_train, Xe_train, _, _, _, _ = merged_folds[fold]\n",
    "    \n",
    "    yDim = Xn_train.shape[1]  # Number of neurons (output dimension)\n",
    "    xDim = Xe_train.shape[1]  # Input dimension (ViT embeddings)\n",
    "    \n",
    "    # Initialize model and load weights\n",
    "    gen_nodes = 128  # Keep this consistent with training\n",
    "    factor = np.min(Xn_train, axis=0) \n",
    "    model = ZIG(yDim, xDim, gen_nodes, factor)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Select the fold's test data\n",
    "    _, _, Xn_test, Xe_test, _, _ = merged_folds[fold]\n",
    "\n",
    "    # Convert test data to PyTorch tensors\n",
    "    Xn_test_tensor = torch.tensor(Xn_test, dtype=torch.float32)\n",
    "    Xe_test_tensor = torch.tensor(Xe_test, dtype=torch.float32)\n",
    "\n",
    "    # Forward pass (no gradients needed since we are evaluating)\n",
    "    with torch.no_grad():\n",
    "        theta, k, p, loc, rate = model(Xe_test_tensor)  # Get model outputs\n",
    "\n",
    "    # Compute probability of the observed data (Xn_test) under the ZIG model\n",
    "    eps = 1e-6  # Small value for numerical stability\n",
    "    mask = (Xn_test_tensor != 0)  # Identify nonzero spikes\n",
    "    mask2 = (Xn_test_tensor == 0)\n",
    "    print(mask)\n",
    "    # Compute the probability of observed spike counts using the ZIG model:\n",
    "    p_zeros = 1 - p  # Probability of being in the zero-inflated state\n",
    "    p_spike = p * torch.exp(-k * torch.log(theta) - (Xn_test_tensor - loc) / theta) * \\\n",
    "              torch.exp((k - 1) * torch.log(torch.clamp(Xn_test_tensor - loc, min=eps)) - torch.lgamma(k))\n",
    "\n",
    "    # Use mask to apply zero-inflation correctly:\n",
    "    test_likelihoods = torch.where(mask, p_spike, p_zeros + eps).cpu().numpy()\n",
    "    event_likelihoods= torch.where(mask, p, 0).cpu().numpy()\n",
    "    event_likelihoods2= torch.where(mask2, p, 0).cpu().numpy()\n",
    "    # Save as a .npy file if a save path is provided\n",
    "    if save_path:\n",
    "        np.save(save_path, test_likelihoods)\n",
    "        print(f\"Saved test likelihoods to {save_path}\")\n",
    "\n",
    "    print(f\"Evaluated fold {fold}. Test likelihoods array shape: {test_likelihoods.shape}\")\n",
    "\n",
    "    return test_likelihoods, event_likelihoods, event_likelihoods2  # Return full 2D array (num_neurons, num_time_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False,  True],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Evaluated fold 0. Test likelihoods array shape: (600, 171)\n"
     ]
    }
   ],
   "source": [
    "test_likelihoods, event_likelihoods, event_likelihoods2=evaluate_model_on_fold(merged_folds, fold=0, model_path=\"/home/maria/MouseViT/trained_models/zig_model_fold.pth\", save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04566071 0.05910847\n"
     ]
    }
   ],
   "source": [
    "a=event_likelihoods2[event_likelihoods2>0]\n",
    "b=event_likelihoods[event_likelihoods>0]\n",
    "print(np.mean(a), np.mean(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
